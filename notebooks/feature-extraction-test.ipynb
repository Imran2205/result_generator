{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "version": "3.6.4",
   "file_extension": ".py",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "name": "python",
   "mimetype": "text/x-python"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "from torchvision.models import resnet50, ResNet50_Weights, resnet152, ResNet152_Weights, AlexNet_Weights, VGG16_BN_Weights\n",
    "from torchvision.models.feature_extraction import get_graph_node_names\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-01T09:18:30.362752Z",
     "iopub.execute_input": "2023-04-01T09:18:30.363432Z",
     "iopub.status.idle": "2023-04-01T09:18:30.371156Z",
     "shell.execute_reply.started": "2023-04-01T09:18:30.363396Z",
     "shell.execute_reply": "2023-04-01T09:18:30.369809Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "m_50 = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2) #  resnet50()\n",
    "m_152 = resnet152(weights=ResNet152_Weights.IMAGENET1K_V2)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-01T09:18:32.252198Z",
     "iopub.execute_input": "2023-04-01T09:18:32.253110Z",
     "iopub.status.idle": "2023-04-01T09:18:34.098076Z",
     "shell.execute_reply.started": "2023-04-01T09:18:32.253056Z",
     "shell.execute_reply": "2023-04-01T09:18:34.097043Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "m_alex = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', weights=AlexNet_Weights.IMAGENET1K_V1)\n",
    "m_vgg16_bn = torch.hub.load('pytorch/vision:v0.10.0', 'vgg16_bn', weights=VGG16_BN_Weights.IMAGENET1K_V1)\n",
    "# train_nodes, eval_nodes = get_graph_node_names(m_vgg16_bn)\n",
    "# m_vgg16_bn"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-01T09:18:40.147603Z",
     "iopub.execute_input": "2023-04-01T09:18:40.148556Z",
     "iopub.status.idle": "2023-04-01T09:18:42.487701Z",
     "shell.execute_reply.started": "2023-04-01T09:18:40.148502Z",
     "shell.execute_reply": "2023-04-01T09:18:42.486492Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "return_nodes_resnet = {\n",
    "    'avgpool': 'out',\n",
    "}\n",
    "return_node_alex = {\n",
    "    'classifier.5': 'out'\n",
    "}\n",
    "return_node_vgg = {\n",
    "    'classifier.5': 'out'\n",
    "}\n",
    "\n",
    "model_50 = create_feature_extractor(m_50, return_nodes=return_nodes_resnet).to(\"cuda:0\")\n",
    "model_152 = create_feature_extractor(m_152, return_nodes=return_nodes_resnet).to(\"cuda:0\")\n",
    "model_alex = create_feature_extractor(m_alex, return_nodes=return_node_alex).to(\"cuda:0\")\n",
    "model_vgg16_bn = create_feature_extractor(m_vgg16_bn, return_nodes=return_node_vgg).to(\"cuda:0\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-01T09:18:42.489973Z",
     "iopub.execute_input": "2023-04-01T09:18:42.490389Z",
     "iopub.status.idle": "2023-04-01T09:18:43.379690Z",
     "shell.execute_reply.started": "2023-04-01T09:18:42.490349Z",
     "shell.execute_reply": "2023-04-01T09:18:43.378639Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "mean = [0.485, 0.456, 0.406] \n",
    "std = [0.229, 0.224, 0.225]\n",
    "\n",
    "transform_norm = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.Normalize(mean, std)]\n",
    ")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-01T09:18:44.363885Z",
     "iopub.execute_input": "2023-04-01T09:18:44.364573Z",
     "iopub.status.idle": "2023-04-01T09:18:44.370354Z",
     "shell.execute_reply.started": "2023-04-01T09:18:44.364534Z",
     "shell.execute_reply": "2023-04-01T09:18:44.369206Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def mse(imageA, imageB):\n",
    "    err = np.sum((imageA.astype(\"float\") - imageB.astype(\"float\")) ** 2)\n",
    "    err /= float(imageA.shape[0] * imageA.shape[1])\n",
    "    return err\n",
    "\n",
    "def compare_images(imageA, imageB):\n",
    "    m = mse(imageA, imageB)\n",
    "    s = ssim(imageA, imageB)\n",
    "    return m, s"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-01T09:18:45.915203Z",
     "iopub.execute_input": "2023-04-01T09:18:45.916136Z",
     "iopub.status.idle": "2023-04-01T09:18:45.922465Z",
     "shell.execute_reply.started": "2023-04-01T09:18:45.916083Z",
     "shell.execute_reply": "2023-04-01T09:18:45.921415Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "csv = \"/kaggle/input/elene-videos/measures.csv\"\n",
    "df_measure = pd.read_csv(csv)\n",
    "df_measure.head()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-01T09:18:47.471188Z",
     "iopub.execute_input": "2023-04-01T09:18:47.471547Z",
     "iopub.status.idle": "2023-04-01T09:18:47.493604Z",
     "shell.execute_reply.started": "2023-04-01T09:18:47.471515Z",
     "shell.execute_reply": "2023-04-01T09:18:47.492715Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# fl = \"/kaggle/input/vqa-video-gt/video_14_segment_4.csv\"\n",
    "# df_gt = pd.read_csv(fl)\n",
    "# df_gt.dropna(how='all', axis=1, inplace=True)\n",
    "# df_gt.dropna(how='all', axis=0, inplace=True)\n",
    "# df_gt_columns = df_gt.columns[1:]\n",
    "\n",
    "# df_gt"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-01T09:18:48.930379Z",
     "iopub.execute_input": "2023-04-01T09:18:48.930872Z",
     "iopub.status.idle": "2023-04-01T09:18:48.935751Z",
     "shell.execute_reply.started": "2023-04-01T09:18:48.930835Z",
     "shell.execute_reply": "2023-04-01T09:18:48.934545Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "csv_folder = \"/kaggle/input/elene-videos/GPV-1 Answers (Combined In Segments)-20230401T085540Z-001/GPV-1 Answers (Combined In Segments)\"\n",
    "gt_folder = \"/kaggle/input/vqa-video-gt\"\n",
    "final_dict = {}\n",
    "for vid_count in range(1, 17):\n",
    "    parent_video = str(vid_count).zfill(3)\n",
    "    video_folder = f\"/kaggle/input/elene-videos/accss_videos_elena-20230320T061114Z-001/accss_videos_elena/video_{parent_video}/trimmed_video\"\n",
    "    \n",
    "    k_f_folds = [\"_\".join(k_i.split('_')[1:]).replace('.mp4', '') for k_i in os.listdir(video_folder) if 'keyframes' in k_i]\n",
    "    \n",
    "    for video_name in k_f_folds:\n",
    "        segment = int(video_name.split('_')[-1].replace('seg', '').replace('.mp4', ''))\n",
    "        print(f\"Video: {vid_count}, Segment: {segment}\")\n",
    "\n",
    "        key_frame_paths = os.path.join(\n",
    "            video_folder,\n",
    "            f'keyframes_{video_name}.mp4'\n",
    "        )\n",
    "\n",
    "        tn = len(os.listdir(key_frame_paths)) + 1\n",
    "\n",
    "        val = \"os.path.join(key_frame_paths, f'{video_name}_{x}.jpeg')\"\n",
    "        tester = f\"os.path.exists({val})\"\n",
    "\n",
    "        images = [eval(val) for x in range(tn) if eval(tester)]\n",
    "        out_resnet_50 = []\n",
    "        out_resnet_152 = []\n",
    "        out_alex = []\n",
    "        out_vgg16_bn = []\n",
    "        out_mse = []\n",
    "        out_ssim = []\n",
    "        out_feat_cos = []\n",
    "        gt_feat_cos = []\n",
    "        \n",
    "        csv_file = os.path.join(\n",
    "            csv_folder,\n",
    "            f\"video-{vid_count}-segment-{segment}.csv\"\n",
    "        )\n",
    "        \n",
    "        df = pd.read_csv(csv_file)\n",
    "        df_columns = df.columns[1:]\n",
    "        \n",
    "        gt_file = os.path.join(\n",
    "            gt_folder,\n",
    "            f\"video_{vid_count}_segment_{segment}.csv\"\n",
    "        )\n",
    "        \n",
    "        if not os.path.exists(gt_file):\n",
    "            continue\n",
    "        \n",
    "        df_gt = pd.read_csv(gt_file)\n",
    "        df_gt.dropna(how='all', axis=1, inplace=True)\n",
    "        df_gt.dropna(how='all', axis=0, inplace=True)\n",
    "        df_gt_columns = df_gt.columns[1:]\n",
    "        \n",
    "        df_measure_slice = df_measure.loc[(df_measure['video'] == vid_count) & (df_measure['segment'] == segment)]\n",
    "        out_feat = list(df_measure_slice['similarity-score'])\n",
    "        \n",
    "        for col_no in tqdm(range(len(df_gt_columns)-1)):\n",
    "            col_1 = torch.FloatTensor(list(df_gt[df_gt_columns[col_no]]))\n",
    "            col_2 = torch.FloatTensor(list(df_gt[df_gt_columns[col_no+1]]))\n",
    "            cos = torch.nn.CosineSimilarity(dim=0, eps=1e-8)\n",
    "            gt_feat = cos(col_1, col_2)\n",
    "            gt_feat_cos.append(float(gt_feat.cpu().numpy()))\n",
    "        \n",
    "        for col_no in tqdm(range(len(df_columns)-1)):\n",
    "            col_1 = torch.FloatTensor(list(df[df_columns[col_no]]))\n",
    "            col_2 = torch.FloatTensor(list(df[df_columns[col_no+1]]))\n",
    "            cos = torch.nn.CosineSimilarity(dim=0, eps=1e-8)\n",
    "            output_feat = cos(col_1, col_2)\n",
    "            out_feat_cos.append(float(output_feat.cpu().numpy()))\n",
    "\n",
    "        for i in tqdm(range(len(images)-1)):\n",
    "            image_1 = np.array(Image.open(images[i]))\n",
    "            image_2 = np.array(Image.open(images[i+1]))\n",
    "            outs_50 = []\n",
    "            for img in [image_1, image_2]:\n",
    "                img_normalized = transform_norm(img).float()\n",
    "                img_normalized = img_normalized.unsqueeze_(0)\n",
    "                img_normalized = img_normalized.to(\"cuda:0\")\n",
    "                with torch.no_grad():\n",
    "                    model_50.eval()  \n",
    "                    output_50 = model_50(img_normalized)[\"out\"].squeeze_(0).squeeze_(1).squeeze_(1)\n",
    "                    outs_50.append(output_50)\n",
    "\n",
    "            cos = torch.nn.CosineSimilarity(dim=0, eps=1e-8)\n",
    "            output_50 = cos(outs_50[0], outs_50[1])\n",
    "            out_resnet_50.append(float(output_50.cpu().numpy()))\n",
    "\n",
    "        for i in tqdm(range(len(images)-1)):\n",
    "            image_1 = np.array(Image.open(images[i]))\n",
    "            image_2 = np.array(Image.open(images[i+1]))\n",
    "            outs_152 = []\n",
    "            for img in [image_1, image_2]:\n",
    "                img_normalized = transform_norm(img).float()\n",
    "                img_normalized = img_normalized.unsqueeze_(0)\n",
    "                img_normalized = img_normalized.to(\"cuda:0\")\n",
    "                with torch.no_grad():\n",
    "                    model_152.eval()   \n",
    "                    output_152 = model_152(img_normalized)[\"out\"].squeeze_(0).squeeze_(1).squeeze_(1)\n",
    "                    outs_152.append(output_152)\n",
    "\n",
    "            cos = torch.nn.CosineSimilarity(dim=0, eps=1e-8)\n",
    "            output_152 = cos(outs_152[0], outs_152[1])\n",
    "            out_resnet_152.append(float(output_152.cpu().numpy()))\n",
    "\n",
    "        for i in tqdm(range(len(images)-1)):\n",
    "            image_1 = np.array(Image.open(images[i]))\n",
    "            image_2 = np.array(Image.open(images[i+1]))\n",
    "            outs_alex = []\n",
    "            for img in [image_1, image_2]:\n",
    "                img_normalized = transform_norm(img).float()\n",
    "                img_normalized = img_normalized.unsqueeze_(0)\n",
    "                img_normalized = img_normalized.to(\"cuda:0\")\n",
    "                with torch.no_grad(): \n",
    "                    model_alex.eval()  \n",
    "                    output_alex = model_alex(img_normalized)[\"out\"].squeeze_(0)\n",
    "                    outs_alex.append(output_alex)\n",
    "\n",
    "            cos = torch.nn.CosineSimilarity(dim=0, eps=1e-8)\n",
    "            output_alex = cos(outs_alex[0], outs_alex[1])\n",
    "            out_alex.append(float(output_alex.cpu().numpy()))\n",
    "\n",
    "        for i in tqdm(range(len(images)-1)):\n",
    "            image_1 = np.array(Image.open(images[i]))\n",
    "            image_2 = np.array(Image.open(images[i+1]))\n",
    "            outs_vgg16_bn = []\n",
    "            for img in [image_1, image_2]:\n",
    "                img_normalized = transform_norm(img).float()\n",
    "                img_normalized = img_normalized.unsqueeze_(0)\n",
    "                img_normalized = img_normalized.to(\"cuda:0\")\n",
    "                with torch.no_grad(): \n",
    "                    model_vgg16_bn.eval()  \n",
    "                    output_vgg16_bn = model_vgg16_bn(img_normalized)[\"out\"].squeeze_(0)\n",
    "                    outs_vgg16_bn.append(output_vgg16_bn)\n",
    "\n",
    "            cos = torch.nn.CosineSimilarity(dim=0, eps=1e-8)\n",
    "            output_vgg16_bn = cos(outs_vgg16_bn[0], outs_vgg16_bn[1])\n",
    "            out_vgg16_bn.append(float(output_vgg16_bn.cpu().numpy()))\n",
    "\n",
    "        for i in tqdm(range(len(images)-1)):\n",
    "            image_1 = np.array(Image.open(images[i]))\n",
    "            image_2 = np.array(Image.open(images[i+1]))\n",
    "\n",
    "            k_f_img = cv2.cvtColor(image_1, cv2.COLOR_BGR2GRAY)\n",
    "            o_f_img = cv2.cvtColor(image_2, cv2.COLOR_BGR2GRAY)\n",
    "            mse_, ssim_ = compare_images(k_f_img, o_f_img)\n",
    "            out_mse.append(mse_)\n",
    "            out_ssim.append(ssim_)\n",
    "            \n",
    "        if vid_count not in final_dict.keys():\n",
    "            final_dict[vid_count] = {}\n",
    "\n",
    "        assert len(out_feat) == len(out_ssim)\n",
    "        assert len(gt_feat_cos) == len(out_ssim)\n",
    "        \n",
    "        final_dict[vid_count][segment] = {\n",
    "            'network': [f'frame-{f}' for f in range(1, len(out_feat)+1)],\n",
    "            'gt-feature': gt_feat_cos,\n",
    "            'gpv-feature': out_feat,\n",
    "            'gpv-feature-cos': out_feat_cos,\n",
    "            'resnet-50': out_resnet_50,\n",
    "            'resnet-152': out_resnet_152,\n",
    "            'alexnet': out_alex,\n",
    "            'vgg16-bn': out_vgg16_bn,\n",
    "            'ssim': out_ssim \n",
    "        }\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-01T09:31:14.545031Z",
     "iopub.execute_input": "2023-04-01T09:31:14.545468Z",
     "iopub.status.idle": "2023-04-01T09:32:46.825994Z",
     "shell.execute_reply.started": "2023-04-01T09:31:14.545430Z",
     "shell.execute_reply": "2023-04-01T09:32:46.824902Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!rm -rf ./*\n",
    "os.makedirs('./csv')\n",
    "os.makedirs('./csv_t')\n",
    "os.makedirs('./plot')\n",
    "os.makedirs('./plot_corr')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-01T09:32:46.827946Z",
     "iopub.execute_input": "2023-04-01T09:32:46.828898Z",
     "iopub.status.idle": "2023-04-01T09:32:47.830000Z",
     "shell.execute_reply.started": "2023-04-01T09:32:46.828856Z",
     "shell.execute_reply": "2023-04-01T09:32:47.828657Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import json\n",
    "\n",
    "with open(\"video_correlation_data.json\", 'w') as f:\n",
    "    f.write(json.dumps(final_dict, indent=4))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-01T09:32:47.831878Z",
     "iopub.execute_input": "2023-04-01T09:32:47.832616Z",
     "iopub.status.idle": "2023-04-01T09:32:47.844633Z",
     "shell.execute_reply.started": "2023-04-01T09:32:47.832570Z",
     "shell.execute_reply": "2023-04-01T09:32:47.843528Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for vid in final_dict.keys():\n",
    "    for seg in final_dict[vid].keys():\n",
    "        data = final_dict[vid][seg]\n",
    "        # data[\"frame\"] = [f for f in range(1, len(final_dict[vid][seg][\"feature\"])+1)]\n",
    "        df = pd.DataFrame(data).T\n",
    "        df.to_csv(f'csv_t/video-{vid}-segment-{seg}.csv', header=False)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-01T09:32:47.847556Z",
     "iopub.execute_input": "2023-04-01T09:32:47.847987Z",
     "iopub.status.idle": "2023-04-01T09:32:47.882229Z",
     "shell.execute_reply.started": "2023-04-01T09:32:47.847951Z",
     "shell.execute_reply": "2023-04-01T09:32:47.881280Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for vid in final_dict.keys():\n",
    "    for seg in final_dict[vid].keys():\n",
    "        data = final_dict[vid][seg]\n",
    "        # data[\"frame\"] = [f for f in range(1, len(final_dict[vid][seg][\"feature\"])+1)]\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(f'csv/video-{vid}-segment-{seg}.csv')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-01T09:32:47.883680Z",
     "iopub.execute_input": "2023-04-01T09:32:47.884043Z",
     "iopub.status.idle": "2023-04-01T09:32:47.906340Z",
     "shell.execute_reply.started": "2023-04-01T09:32:47.884008Z",
     "shell.execute_reply": "2023-04-01T09:32:47.905419Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# for vid in final_dict.keys():\n",
    "#     for seg in final_dict[vid].keys():\n",
    "#         data = final_dict[vid][seg]\n",
    "#         fig = plt.figure(figsize=(12, 8))\n",
    "#         linestyle_dict = {\n",
    "#              'solid': 'solid',      # Same as (0, ()) or '-'\n",
    "#              'dotted': 'dotted',    # Same as (0, (1, 1)) or ':'\n",
    "#              'dashed': 'dashed',    # Same as '--'\n",
    "#              'dashdot': 'dashdot',\n",
    "#\n",
    "#              'loosely dotted':        (0, (1, 10)),\n",
    "#              'dotted':                (0, (1, 1)),\n",
    "#              'densely dotted':        (0, (1, 1)),\n",
    "#              'long dash with offset': (5, (10, 3)),\n",
    "#              'loosely dashed':        (0, (5, 10)),\n",
    "#              'dashed 2':              (0, (5, 5)),\n",
    "#              'densely dashed':        (0, (5, 1)),\n",
    "#\n",
    "#              'loosely dashdotted':    (0, (3, 10, 1, 10)),\n",
    "#              'dashdotted':            (0, (3, 5, 1, 5)),\n",
    "#              'densely dashdotted':    (0, (3, 1, 1, 1)),\n",
    "#\n",
    "#              'dashdotdotted':         (0, (3, 5, 1, 5, 1, 5)),\n",
    "#              'loosely dashdotdotted': (0, (3, 10, 1, 10, 1, 10)),\n",
    "#              'densely dashdotdotted': (0, (3, 1, 1, 1, 1, 1))\n",
    "#         }\n",
    "#\n",
    "#         legends = [\"resnet-50\", 'resnet-152', 'alexnet', 'vgg16-bn', 'SSIM', 'gpv-feature', 'gt-feature']\n",
    "#\n",
    "#         plt.plot(data['network'], data['resnet-50'], color='green', linestyle=linestyle_dict['solid'], marker='o', markerfacecolor='green', markersize=0)\n",
    "#         plt.plot(data['network'], data['resnet-152'], color='blue', linestyle=linestyle_dict['dotted'], marker='o', markerfacecolor='blue', markersize=0)\n",
    "#         plt.plot(data['network'], data['alexnet'], color='orange', linestyle=linestyle_dict['dashed'], marker='o', markerfacecolor='orange', markersize=0)\n",
    "#         plt.plot(data['network'], data['vgg16-bn'], color='red', linestyle=linestyle_dict['dashdot'], marker='o', markerfacecolor='red', markersize=0)\n",
    "#         plt.plot(data['network'], data['ssim'], color='gray', linestyle=linestyle_dict['dashdot'], marker='o', markerfacecolor='red', markersize=0)\n",
    "#         plt.plot(data['network'], data['gpv-feature-cos'], color='black', linestyle=linestyle_dict['densely dashdotted'], marker='o', markerfacecolor='black',\n",
    "#                  markersize=0, linewidth=3)\n",
    "#         plt.plot(data['network'], data['gt-feature'], color='purple', linestyle=linestyle_dict['densely dashdotdotted'], marker='o', markerfacecolor='purple',\n",
    "#                  markersize=0, linewidth=3)\n",
    "#\n",
    "#         plt.legend(legends, bbox_to_anchor=(1.00, 1.00), ncol=1)\n",
    "#         plt.xticks(rotation = 90)\n",
    "#         plt.title(f'video-{vid}-segment-{seg}.png')\n",
    "#\n",
    "#         plt.ylim([0, 1.0])\n",
    "#\n",
    "#         plt.tight_layout()\n",
    "#         plt.savefig(f'plot/video-{vid}-segment-{seg}.png')\n",
    "#         plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-04-01T09:32:47.908015Z",
     "iopub.execute_input": "2023-04-01T09:32:47.908370Z",
     "iopub.status.idle": "2023-04-01T09:32:54.779808Z",
     "shell.execute_reply.started": "2023-04-01T09:32:47.908336Z",
     "shell.execute_reply": "2023-04-01T09:32:54.778621Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ! pip install kaleido"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-29T13:19:32.283304Z",
     "iopub.execute_input": "2023-03-29T13:19:32.283701Z",
     "iopub.status.idle": "2023-03-29T13:19:32.289582Z",
     "shell.execute_reply.started": "2023-03-29T13:19:32.283662Z",
     "shell.execute_reply": "2023-03-29T13:19:32.288395Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# ! conda install -c conda-forge python-kaleido -y\n",
    "# ! pip uninstall kaleido\n",
    "# ! pip install -q condacolab\n",
    "# import condacolab\n",
    "# condacolab.install()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-29T13:19:32.291155Z",
     "iopub.execute_input": "2023-03-29T13:19:32.291516Z",
     "iopub.status.idle": "2023-03-29T13:19:32.300702Z",
     "shell.execute_reply.started": "2023-03-29T13:19:32.291481Z",
     "shell.execute_reply": "2023-03-29T13:19:32.299753Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# import plotly.graph_objects as go\n",
    "# import plotly.express as px\n",
    "#\n",
    "# for vid in final_dict.keys():\n",
    "#     for seg in final_dict[vid].keys():\n",
    "#         data = final_dict[vid][seg]\n",
    "#\n",
    "#         layout = dict(plot_bgcolor='white',\n",
    "#                       title=f'video-{vid}-segment-{seg}.png',\n",
    "#                       width=500,\n",
    "#                       height=500,\n",
    "#                       margin=dict(t=30, l=30, r=30, b=30),\n",
    "#                       xaxis=dict(title='gt Feature Similarity',\n",
    "#                                  range=[0.0, 1.0],\n",
    "#                                  linecolor='#d9d9d9',\n",
    "#                                  showgrid=False,\n",
    "#                                  mirror=True),\n",
    "#                       yaxis=dict(title='GPV Feature Similarity',\n",
    "#                                  range=[0.0, 1.0],\n",
    "#                                  linecolor='#d9d9d9',\n",
    "#                                  showgrid=False,\n",
    "#                                  mirror=True))\n",
    "#\n",
    "#         fig_tmp = px.scatter(x=data['gt-feature'],\n",
    "#                           y=data['gpv-feature'],\n",
    "#                           trendline='ols')\n",
    "#\n",
    "#         fig = go.Figure(data=fig_tmp.data, layout=layout)\n",
    "#\n",
    "#         fig.show()\n",
    "#         # fig.write_image(f'plot_corr/video-{vid}-segment-{seg}-corr.png')\n",
    "#         img_bytes = fig.to_image(format=\"png\")\n",
    "#\n",
    "#         with open(f'plot_corr/video-{vid}-segment-{seg}-corr.png', 'wb') as f:\n",
    "#             f.write(img_bytes)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-03-29T13:19:32.302009Z",
     "iopub.execute_input": "2023-03-29T13:19:32.302411Z",
     "iopub.status.idle": "2023-03-29T13:19:38.114918Z",
     "shell.execute_reply.started": "2023-03-29T13:19:32.302373Z",
     "shell.execute_reply": "2023-03-29T13:19:38.113148Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}